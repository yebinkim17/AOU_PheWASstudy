{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print('1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import gzip\n",
    "import nbformat\n",
    "from nbconvert.preprocessors import CellExecutionError\n",
    "from nbconvert.preprocessors import ExecutePreprocessor\n",
    "import os\n",
    "import shutil\n",
    "import tensorflow as tf\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---[ Change this to be the name of the notebook in the current working directory that you wish to run. ]-----------\n",
    "NOTEBOOK_TO_RUN = 'Aldy running.ipynb'\n",
    "\n",
    "#---[ Change the following to 'Python' if you have a Python notebook, or to 'R' if you have an R notebook.\n",
    "KERNEL = 'R'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed notebook will be written to filename \"Aldy running_20230418_154122.ipynb\" on the local disk and the workspace bucket.\n"
     ]
    }
   ],
   "source": [
    "TIMESTAMP_FILE_SUFFIX = time.strftime('_%Y%m%d_%H%M%S.ipynb')\n",
    "OUTPUT_NOTEBOOK = NOTEBOOK_TO_RUN.replace('.ipynb', TIMESTAMP_FILE_SUFFIX)\n",
    "\n",
    "print(f'Executed notebook will be written to filename \"{OUTPUT_NOTEBOOK}\" on the local disk and the workspace bucket.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hail logs, if any, will be copied to gs://fc-secure-efde03ca-418d-445e-84f1-df6f8f3f35d4/hail-logs/20230418\n"
     ]
    }
   ],
   "source": [
    "DATESTAMP = time.strftime('%Y%m%d')\n",
    "HAIL_LOG_DIR_FOR_PROVENANCE = os.path.join(os.getenv('WORKSPACE_BUCKET'), 'hail-logs', DATESTAMP)\n",
    "\n",
    "print(f'Hail logs, if any, will be copied to {HAIL_LOG_DIR_FOR_PROVENANCE}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_kernel(kernel):\n",
    "    return 'ir' if kernel.lower() == 'r' else 'python3'\n",
    "\n",
    "KERNEL_NAME = get_kernel(KERNEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[0;1;31mSystem has not been booted with systemd as init system (PID 1). Can't operate.\u001b[0m\n",
      "\u001b[0;1;31mFailed to create bus connection: Host is down\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote executed notebook to gs://fc-secure-efde03ca-418d-445e-84f1-df6f8f3f35d4/notebooks/Aldy running_20230418_154122.ipynb\n"
     ]
    }
   ],
   "source": [
    "# See also https://nbconvert.readthedocs.io/en/latest/execute_api.html\n",
    "with open(NOTEBOOK_TO_RUN) as f_in:\n",
    "    nb = nbformat.read(f_in, as_version=4)\n",
    "    ep = ExecutePreprocessor(timeout=-1, kernel_name=KERNEL_NAME)\n",
    "    try:\n",
    "        out = ep.preprocess(nb, {'metadata': {'path': ''}})\n",
    "    except CellExecutionError:\n",
    "        out = None\n",
    "        print(f'''Error executing the notebook \"{NOTEBOOK_TO_RUN}\".\n",
    "        See notebook \"{OUTPUT_NOTEBOOK}\" for the traceback.''')\n",
    "    finally:\n",
    "        with open(OUTPUT_NOTEBOOK, mode='w', encoding='utf-8') as f_out:\n",
    "            nbformat.write(nb, f_out)\n",
    "        # Save the executed notebook to the workspace bucket.\n",
    "        output_notebook_path = os.path.join(os.getenv('WORKSPACE_BUCKET'), 'notebooks', OUTPUT_NOTEBOOK)\n",
    "        tf.io.gfile.copy(src=OUTPUT_NOTEBOOK, dst=output_notebook_path)\n",
    "        print(f'Wrote executed notebook to {output_notebook_path}')\n",
    "\n",
    "# Save the hail logs, if any, to the workspace bucket.\n",
    "for hail_log in glob.glob('hail*.log'):\n",
    "    with open(hail_log, 'rb') as f_in:\n",
    "        compressed_hail_log = f'{hail_log}.gz'\n",
    "        with gzip.open(compressed_hail_log, 'wb') as f_out:\n",
    "            shutil.copyfileobj(f_in, f_out)\n",
    "    hail_log_path = os.path.join(HAIL_LOG_DIR_FOR_PROVENANCE, compressed_hail_log)\n",
    "    if not tf.io.gfile.exists(hail_log_path):\n",
    "        tf.io.gfile.copy(src=compressed_hail_log, dst=hail_log_path)\n",
    "        print(f'Wrote hail log to {hail_log_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
