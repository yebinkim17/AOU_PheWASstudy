{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample Set 1\n",
    "\n",
    "WGS, White, Female or Male\n",
    "\n",
    "Random Selection # 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The data will be written to gs://fc-secure-efde03ca-418d-445e-84f1-df6f8f3f35d4/bq_exports/yebin@researchallofus.org/20230516/person_91554429/person_91554429_*.csv. Use this path when reading the data into your notebooks in the future.\n",
      "\n",
      "Loading gs://fc-secure-efde03ca-418d-445e-84f1-df6f8f3f35d4/bq_exports/yebin@researchallofus.org/20230516/person_91554429/person_91554429_000000000000.csv.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>50569</li><li>5</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 50569\n",
       "\\item 5\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 50569\n",
       "2. 5\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 50569     5"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A tibble: 5 × 5</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>person_id</th><th scope=col>date_of_birth</th><th scope=col>race</th><th scope=col>ethnicity</th><th scope=col>sex_at_birth</th></tr>\n",
       "\t<tr><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>2267068</td><td>1950-06-15 00:00:00 UTC</td><td>White</td><td>Hispanic or Latino</td><td>Male</td></tr>\n",
       "\t<tr><td>1547400</td><td>1953-06-15 00:00:00 UTC</td><td>White</td><td>Hispanic or Latino</td><td>Male</td></tr>\n",
       "\t<tr><td>1901649</td><td>1960-06-15 00:00:00 UTC</td><td>White</td><td>Hispanic or Latino</td><td>Male</td></tr>\n",
       "\t<tr><td>3590759</td><td>1961-06-15 00:00:00 UTC</td><td>White</td><td>Hispanic or Latino</td><td>Male</td></tr>\n",
       "\t<tr><td>2920542</td><td>1964-06-15 00:00:00 UTC</td><td>White</td><td>Hispanic or Latino</td><td>Male</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A tibble: 5 × 5\n",
       "\\begin{tabular}{lllll}\n",
       " person\\_id & date\\_of\\_birth & race & ethnicity & sex\\_at\\_birth\\\\\n",
       " <dbl> & <chr> & <chr> & <chr> & <chr>\\\\\n",
       "\\hline\n",
       "\t 2267068 & 1950-06-15 00:00:00 UTC & White & Hispanic or Latino & Male\\\\\n",
       "\t 1547400 & 1953-06-15 00:00:00 UTC & White & Hispanic or Latino & Male\\\\\n",
       "\t 1901649 & 1960-06-15 00:00:00 UTC & White & Hispanic or Latino & Male\\\\\n",
       "\t 3590759 & 1961-06-15 00:00:00 UTC & White & Hispanic or Latino & Male\\\\\n",
       "\t 2920542 & 1964-06-15 00:00:00 UTC & White & Hispanic or Latino & Male\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A tibble: 5 × 5\n",
       "\n",
       "| person_id &lt;dbl&gt; | date_of_birth &lt;chr&gt; | race &lt;chr&gt; | ethnicity &lt;chr&gt; | sex_at_birth &lt;chr&gt; |\n",
       "|---|---|---|---|---|\n",
       "| 2267068 | 1950-06-15 00:00:00 UTC | White | Hispanic or Latino | Male |\n",
       "| 1547400 | 1953-06-15 00:00:00 UTC | White | Hispanic or Latino | Male |\n",
       "| 1901649 | 1960-06-15 00:00:00 UTC | White | Hispanic or Latino | Male |\n",
       "| 3590759 | 1961-06-15 00:00:00 UTC | White | Hispanic or Latino | Male |\n",
       "| 2920542 | 1964-06-15 00:00:00 UTC | White | Hispanic or Latino | Male |\n",
       "\n"
      ],
      "text/plain": [
       "  person_id date_of_birth           race  ethnicity          sex_at_birth\n",
       "1 2267068   1950-06-15 00:00:00 UTC White Hispanic or Latino Male        \n",
       "2 1547400   1953-06-15 00:00:00 UTC White Hispanic or Latino Male        \n",
       "3 1901649   1960-06-15 00:00:00 UTC White Hispanic or Latino Male        \n",
       "4 3590759   1961-06-15 00:00:00 UTC White Hispanic or Latino Male        \n",
       "5 2920542   1964-06-15 00:00:00 UTC White Hispanic or Latino Male        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "library(tidyverse)\n",
    "library(bigrquery)\n",
    "\n",
    "# This query represents dataset \"All_WGS_White_FM\" for domain \"person\" and was generated for All of Us Controlled Tier Dataset v6\n",
    "dataset_91554429_person_sql <- paste(\"\n",
    "    SELECT\n",
    "        person.person_id,\n",
    "        person.birth_datetime as date_of_birth,\n",
    "        p_race_concept.concept_name as race,\n",
    "        p_ethnicity_concept.concept_name as ethnicity,\n",
    "        p_sex_at_birth_concept.concept_name as sex_at_birth \n",
    "    FROM\n",
    "        `person` person \n",
    "    LEFT JOIN\n",
    "        `concept` p_race_concept \n",
    "            ON person.race_concept_id = p_race_concept.concept_id \n",
    "    LEFT JOIN\n",
    "        `concept` p_ethnicity_concept \n",
    "            ON person.ethnicity_concept_id = p_ethnicity_concept.concept_id \n",
    "    LEFT JOIN\n",
    "        `concept` p_sex_at_birth_concept \n",
    "            ON person.sex_at_birth_concept_id = p_sex_at_birth_concept.concept_id  \n",
    "    WHERE\n",
    "        person.PERSON_ID IN (\n",
    "            SELECT\n",
    "                distinct person_id  \n",
    "            FROM\n",
    "                `cb_search_person` cb_search_person  \n",
    "            WHERE\n",
    "                cb_search_person.person_id IN (\n",
    "                    SELECT\n",
    "                        person_id \n",
    "                    FROM\n",
    "                        `cb_search_person` p \n",
    "                    WHERE\n",
    "                        has_whole_genome_variant = 1 \n",
    "                ) \n",
    "                AND cb_search_person.person_id IN (\n",
    "                    SELECT\n",
    "                        person_id \n",
    "                    FROM\n",
    "                        `person` p \n",
    "                    WHERE\n",
    "                        race_concept_id IN (8527) \n",
    "                ) \n",
    "                AND cb_search_person.person_id IN (\n",
    "                    SELECT\n",
    "                        person_id \n",
    "                    FROM\n",
    "                        `person` p \n",
    "                    WHERE\n",
    "                        sex_at_birth_concept_id IN (45878463, 45880669) \n",
    "                ) \n",
    "            )\", sep=\"\")\n",
    "\n",
    "# Formulate a Cloud Storage destination path for the data exported from BigQuery.\n",
    "# NOTE: By default data exported multiple times on the same day will overwrite older copies.\n",
    "#       But data exported on a different days will write to a new location so that historical\n",
    "#       copies can be kept as the dataset definition is changed.\n",
    "person_91554429_path <- file.path(\n",
    "  Sys.getenv(\"WORKSPACE_BUCKET\"),\n",
    "  \"bq_exports\",\n",
    "  Sys.getenv(\"OWNER_EMAIL\"),\n",
    "  strftime(lubridate::now(), \"%Y%m%d\"),  # Comment out this line if you want the export to always overwrite.\n",
    "  \"person_91554429\",\n",
    "  \"person_91554429_*.csv\")\n",
    "message(str_glue('The data will be written to {person_91554429_path}. Use this path when reading ',\n",
    "                 'the data into your notebooks in the future.'))\n",
    "\n",
    "# Perform the query and export the dataset to Cloud Storage as CSV files.\n",
    "# NOTE: You only need to run `bq_table_save` once. After that, you can\n",
    "#       just read data from the CSVs in Cloud Storage.\n",
    "bq_table_save(\n",
    "  bq_dataset_query(Sys.getenv(\"WORKSPACE_CDR\"), dataset_91554429_person_sql, billing = Sys.getenv(\"GOOGLE_PROJECT\")),\n",
    "  person_91554429_path,\n",
    "  destination_format = \"CSV\")\n",
    "\n",
    "# Read the data directly from Cloud Storage into memory.\n",
    "# NOTE: Alternatively you can `gsutil -m cp {person_91554429_path}` to copy these files\n",
    "#       to the Jupyter disk.\n",
    "read_bq_export_from_workspace_bucket <- function(export_path) {\n",
    "  col_types <- cols(race = col_character(), ethnicity = col_character(), sex_at_birth = col_character())\n",
    "  bind_rows(\n",
    "    map(system2('gsutil', args = c('ls', export_path), stdout = TRUE, stderr = TRUE),\n",
    "        function(csv) {\n",
    "          message(str_glue('Loading {csv}.'))\n",
    "          chunk <- read_csv(pipe(str_glue('gsutil cat {csv}')), col_types = col_types, show_col_types = FALSE)\n",
    "          if (is.null(col_types)) {\n",
    "            col_types <- spec(chunk)\n",
    "          }\n",
    "          chunk\n",
    "        }))\n",
    "}\n",
    "dataset_91554429_person_df <- read_bq_export_from_workspace_bucket(person_91554429_path)\n",
    "\n",
    "dim(dataset_91554429_person_df)\n",
    "\n",
    "head(dataset_91554429_person_df, 5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(1)\n",
    "select_patients = sample(x=1:dim(data)[1],size=1000)\n",
    "select_data = data[select_patients,]\n",
    "write.csv(select_data,file=\"/home/jupyter/workspaces/multiallelicgenesinvestigation/OUTPUT_SET_1/SAMPLE_SET_1.csv\",quote=FALSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample Set 2\n",
    "\n",
    "WGS, Black, Female or Male\n",
    "\n",
    "Random Selection # 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The data will be written to gs://fc-secure-efde03ca-418d-445e-84f1-df6f8f3f35d4/bq_exports/yebin@researchallofus.org/20230516/person_65641764/person_65641764_*.csv. Use this path when reading the data into your notebooks in the future.\n",
      "\n",
      "Loading gs://fc-secure-efde03ca-418d-445e-84f1-df6f8f3f35d4/bq_exports/yebin@researchallofus.org/20230516/person_65641764/person_65641764_000000000000.csv.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>21354</li><li>5</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 21354\n",
       "\\item 5\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 21354\n",
       "2. 5\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 21354     5"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A tibble: 5 × 5</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>person_id</th><th scope=col>date_of_birth</th><th scope=col>race</th><th scope=col>ethnicity</th><th scope=col>sex_at_birth</th></tr>\n",
       "\t<tr><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>2632011</td><td>1954-06-15 00:00:00 UTC</td><td>Black or African American</td><td>Hispanic or Latino</td><td>Male</td></tr>\n",
       "\t<tr><td>1816469</td><td>1981-06-15 00:00:00 UTC</td><td>Black or African American</td><td>Hispanic or Latino</td><td>Male</td></tr>\n",
       "\t<tr><td>3372940</td><td>1994-06-15 00:00:00 UTC</td><td>Black or African American</td><td>Hispanic or Latino</td><td>Male</td></tr>\n",
       "\t<tr><td>1868967</td><td>1960-06-15 00:00:00 UTC</td><td>Black or African American</td><td>Hispanic or Latino</td><td>Male</td></tr>\n",
       "\t<tr><td>1864790</td><td>1968-06-15 00:00:00 UTC</td><td>Black or African American</td><td>Hispanic or Latino</td><td>Male</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A tibble: 5 × 5\n",
       "\\begin{tabular}{lllll}\n",
       " person\\_id & date\\_of\\_birth & race & ethnicity & sex\\_at\\_birth\\\\\n",
       " <dbl> & <chr> & <chr> & <chr> & <chr>\\\\\n",
       "\\hline\n",
       "\t 2632011 & 1954-06-15 00:00:00 UTC & Black or African American & Hispanic or Latino & Male\\\\\n",
       "\t 1816469 & 1981-06-15 00:00:00 UTC & Black or African American & Hispanic or Latino & Male\\\\\n",
       "\t 3372940 & 1994-06-15 00:00:00 UTC & Black or African American & Hispanic or Latino & Male\\\\\n",
       "\t 1868967 & 1960-06-15 00:00:00 UTC & Black or African American & Hispanic or Latino & Male\\\\\n",
       "\t 1864790 & 1968-06-15 00:00:00 UTC & Black or African American & Hispanic or Latino & Male\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A tibble: 5 × 5\n",
       "\n",
       "| person_id &lt;dbl&gt; | date_of_birth &lt;chr&gt; | race &lt;chr&gt; | ethnicity &lt;chr&gt; | sex_at_birth &lt;chr&gt; |\n",
       "|---|---|---|---|---|\n",
       "| 2632011 | 1954-06-15 00:00:00 UTC | Black or African American | Hispanic or Latino | Male |\n",
       "| 1816469 | 1981-06-15 00:00:00 UTC | Black or African American | Hispanic or Latino | Male |\n",
       "| 3372940 | 1994-06-15 00:00:00 UTC | Black or African American | Hispanic or Latino | Male |\n",
       "| 1868967 | 1960-06-15 00:00:00 UTC | Black or African American | Hispanic or Latino | Male |\n",
       "| 1864790 | 1968-06-15 00:00:00 UTC | Black or African American | Hispanic or Latino | Male |\n",
       "\n"
      ],
      "text/plain": [
       "  person_id date_of_birth           race                     \n",
       "1 2632011   1954-06-15 00:00:00 UTC Black or African American\n",
       "2 1816469   1981-06-15 00:00:00 UTC Black or African American\n",
       "3 3372940   1994-06-15 00:00:00 UTC Black or African American\n",
       "4 1868967   1960-06-15 00:00:00 UTC Black or African American\n",
       "5 1864790   1968-06-15 00:00:00 UTC Black or African American\n",
       "  ethnicity          sex_at_birth\n",
       "1 Hispanic or Latino Male        \n",
       "2 Hispanic or Latino Male        \n",
       "3 Hispanic or Latino Male        \n",
       "4 Hispanic or Latino Male        \n",
       "5 Hispanic or Latino Male        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "library(tidyverse)\n",
    "library(bigrquery)\n",
    "\n",
    "# This query represents dataset \"All_WGS_Black_FM\" for domain \"person\" and was generated for All of Us Controlled Tier Dataset v6\n",
    "dataset_65641764_person_sql <- paste(\"\n",
    "    SELECT\n",
    "        person.person_id,\n",
    "        person.birth_datetime as date_of_birth,\n",
    "        p_race_concept.concept_name as race,\n",
    "        p_ethnicity_concept.concept_name as ethnicity,\n",
    "        p_sex_at_birth_concept.concept_name as sex_at_birth \n",
    "    FROM\n",
    "        `person` person \n",
    "    LEFT JOIN\n",
    "        `concept` p_race_concept \n",
    "            ON person.race_concept_id = p_race_concept.concept_id \n",
    "    LEFT JOIN\n",
    "        `concept` p_ethnicity_concept \n",
    "            ON person.ethnicity_concept_id = p_ethnicity_concept.concept_id \n",
    "    LEFT JOIN\n",
    "        `concept` p_sex_at_birth_concept \n",
    "            ON person.sex_at_birth_concept_id = p_sex_at_birth_concept.concept_id  \n",
    "    WHERE\n",
    "        person.PERSON_ID IN (\n",
    "            SELECT\n",
    "                distinct person_id  \n",
    "            FROM\n",
    "                `cb_search_person` cb_search_person  \n",
    "            WHERE\n",
    "                cb_search_person.person_id IN (\n",
    "                    SELECT\n",
    "                        person_id \n",
    "                    FROM\n",
    "                        `cb_search_person` p \n",
    "                    WHERE\n",
    "                        has_whole_genome_variant = 1 \n",
    "                ) \n",
    "                AND cb_search_person.person_id IN (\n",
    "                    SELECT\n",
    "                        person_id \n",
    "                    FROM\n",
    "                        `person` p \n",
    "                    WHERE\n",
    "                        race_concept_id IN (8516) \n",
    "                ) \n",
    "                AND cb_search_person.person_id IN (\n",
    "                    SELECT\n",
    "                        person_id \n",
    "                    FROM\n",
    "                        `person` p \n",
    "                    WHERE\n",
    "                        sex_at_birth_concept_id IN (45878463, 45880669) \n",
    "                ) \n",
    "            )\", sep=\"\")\n",
    "\n",
    "# Formulate a Cloud Storage destination path for the data exported from BigQuery.\n",
    "# NOTE: By default data exported multiple times on the same day will overwrite older copies.\n",
    "#       But data exported on a different days will write to a new location so that historical\n",
    "#       copies can be kept as the dataset definition is changed.\n",
    "person_65641764_path <- file.path(\n",
    "  Sys.getenv(\"WORKSPACE_BUCKET\"),\n",
    "  \"bq_exports\",\n",
    "  Sys.getenv(\"OWNER_EMAIL\"),\n",
    "  strftime(lubridate::now(), \"%Y%m%d\"),  # Comment out this line if you want the export to always overwrite.\n",
    "  \"person_65641764\",\n",
    "  \"person_65641764_*.csv\")\n",
    "message(str_glue('The data will be written to {person_65641764_path}. Use this path when reading ',\n",
    "                 'the data into your notebooks in the future.'))\n",
    "\n",
    "# Perform the query and export the dataset to Cloud Storage as CSV files.\n",
    "# NOTE: You only need to run `bq_table_save` once. After that, you can\n",
    "#       just read data from the CSVs in Cloud Storage.\n",
    "bq_table_save(\n",
    "  bq_dataset_query(Sys.getenv(\"WORKSPACE_CDR\"), dataset_65641764_person_sql, billing = Sys.getenv(\"GOOGLE_PROJECT\")),\n",
    "  person_65641764_path,\n",
    "  destination_format = \"CSV\")\n",
    "\n",
    "\n",
    "\n",
    "# Read the data directly from Cloud Storage into memory.\n",
    "# NOTE: Alternatively you can `gsutil -m cp {person_65641764_path}` to copy these files\n",
    "#       to the Jupyter disk.\n",
    "read_bq_export_from_workspace_bucket <- function(export_path) {\n",
    "  col_types <- cols(race = col_character(), ethnicity = col_character(), sex_at_birth = col_character())\n",
    "  bind_rows(\n",
    "    map(system2('gsutil', args = c('ls', export_path), stdout = TRUE, stderr = TRUE),\n",
    "        function(csv) {\n",
    "          message(str_glue('Loading {csv}.'))\n",
    "          chunk <- read_csv(pipe(str_glue('gsutil cat {csv}')), col_types = col_types, show_col_types = FALSE)\n",
    "          if (is.null(col_types)) {\n",
    "            col_types <- spec(chunk)\n",
    "          }\n",
    "          chunk\n",
    "        }))\n",
    "}\n",
    "dataset_65641764_person_df <- read_bq_export_from_workspace_bucket(person_65641764_path)\n",
    "\n",
    "dim(dataset_65641764_person_df)\n",
    "\n",
    "head(dataset_65641764_person_df, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dataset_65641764_person_df\n",
    "\n",
    "set.seed(1)\n",
    "select_patients = sample(x=1:dim(data)[1],size=1000)\n",
    "select_data = data[select_patients,]\n",
    "write.csv(select_data,file=\"/home/jupyter/workspaces/multiallelicgenesinvestigation/OUTPUT_SET_2/SAMPLE_SET_2.csv\",quote=FALSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "## write.csv(random2_data,file=\"/home/jupyter/workspaces/multiallelicgenesinvestigation/OUTPUT_SET_2/SAMPLE_SET_2.csv\",quote=FALSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample Set 3\n",
    "\n",
    "WGS, Asian, Female or Male\n",
    "\n",
    "Random Selection # 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The data will be written to gs://fc-secure-efde03ca-418d-445e-84f1-df6f8f3f35d4/bq_exports/yebin@researchallofus.org/20230516/person_25218662/person_25218662_*.csv. Use this path when reading the data into your notebooks in the future.\n",
      "\n",
      "Loading gs://fc-secure-efde03ca-418d-445e-84f1-df6f8f3f35d4/bq_exports/yebin@researchallofus.org/20230516/person_25218662/person_25218662_000000000000.csv.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>3047</li><li>5</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 3047\n",
       "\\item 5\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 3047\n",
       "2. 5\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 3047    5"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A tibble: 5 × 5</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>person_id</th><th scope=col>date_of_birth</th><th scope=col>race</th><th scope=col>ethnicity</th><th scope=col>sex_at_birth</th></tr>\n",
       "\t<tr><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>1794805</td><td>2001-06-15 00:00:00 UTC</td><td>Asian</td><td>Not Hispanic or Latino</td><td>I prefer not to answer</td></tr>\n",
       "\t<tr><td>1915329</td><td>1991-06-15 00:00:00 UTC</td><td>Asian</td><td>Not Hispanic or Latino</td><td>PMI: Skip             </td></tr>\n",
       "\t<tr><td>2410941</td><td>1945-06-15 00:00:00 UTC</td><td>Asian</td><td>Not Hispanic or Latino</td><td>PMI: Skip             </td></tr>\n",
       "\t<tr><td>1726080</td><td>2000-06-15 00:00:00 UTC</td><td>Asian</td><td>Not Hispanic or Latino</td><td>PMI: Skip             </td></tr>\n",
       "\t<tr><td>3032547</td><td>1982-06-15 00:00:00 UTC</td><td>Asian</td><td>Not Hispanic or Latino</td><td>PMI: Skip             </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A tibble: 5 × 5\n",
       "\\begin{tabular}{lllll}\n",
       " person\\_id & date\\_of\\_birth & race & ethnicity & sex\\_at\\_birth\\\\\n",
       " <dbl> & <chr> & <chr> & <chr> & <chr>\\\\\n",
       "\\hline\n",
       "\t 1794805 & 2001-06-15 00:00:00 UTC & Asian & Not Hispanic or Latino & I prefer not to answer\\\\\n",
       "\t 1915329 & 1991-06-15 00:00:00 UTC & Asian & Not Hispanic or Latino & PMI: Skip             \\\\\n",
       "\t 2410941 & 1945-06-15 00:00:00 UTC & Asian & Not Hispanic or Latino & PMI: Skip             \\\\\n",
       "\t 1726080 & 2000-06-15 00:00:00 UTC & Asian & Not Hispanic or Latino & PMI: Skip             \\\\\n",
       "\t 3032547 & 1982-06-15 00:00:00 UTC & Asian & Not Hispanic or Latino & PMI: Skip             \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A tibble: 5 × 5\n",
       "\n",
       "| person_id &lt;dbl&gt; | date_of_birth &lt;chr&gt; | race &lt;chr&gt; | ethnicity &lt;chr&gt; | sex_at_birth &lt;chr&gt; |\n",
       "|---|---|---|---|---|\n",
       "| 1794805 | 2001-06-15 00:00:00 UTC | Asian | Not Hispanic or Latino | I prefer not to answer |\n",
       "| 1915329 | 1991-06-15 00:00:00 UTC | Asian | Not Hispanic or Latino | PMI: Skip              |\n",
       "| 2410941 | 1945-06-15 00:00:00 UTC | Asian | Not Hispanic or Latino | PMI: Skip              |\n",
       "| 1726080 | 2000-06-15 00:00:00 UTC | Asian | Not Hispanic or Latino | PMI: Skip              |\n",
       "| 3032547 | 1982-06-15 00:00:00 UTC | Asian | Not Hispanic or Latino | PMI: Skip              |\n",
       "\n"
      ],
      "text/plain": [
       "  person_id date_of_birth           race  ethnicity             \n",
       "1 1794805   2001-06-15 00:00:00 UTC Asian Not Hispanic or Latino\n",
       "2 1915329   1991-06-15 00:00:00 UTC Asian Not Hispanic or Latino\n",
       "3 2410941   1945-06-15 00:00:00 UTC Asian Not Hispanic or Latino\n",
       "4 1726080   2000-06-15 00:00:00 UTC Asian Not Hispanic or Latino\n",
       "5 3032547   1982-06-15 00:00:00 UTC Asian Not Hispanic or Latino\n",
       "  sex_at_birth          \n",
       "1 I prefer not to answer\n",
       "2 PMI: Skip             \n",
       "3 PMI: Skip             \n",
       "4 PMI: Skip             \n",
       "5 PMI: Skip             "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "library(tidyverse)\n",
    "library(bigrquery)\n",
    "\n",
    "# This query represents dataset \"All_WGS_Asian_FM\" for domain \"person\" and was generated for All of Us Controlled Tier Dataset v6\n",
    "dataset_25218662_person_sql <- paste(\"\n",
    "    SELECT\n",
    "        person.person_id,\n",
    "        person.birth_datetime as date_of_birth,\n",
    "        p_race_concept.concept_name as race,\n",
    "        p_ethnicity_concept.concept_name as ethnicity,\n",
    "        p_sex_at_birth_concept.concept_name as sex_at_birth \n",
    "    FROM\n",
    "        `person` person \n",
    "    LEFT JOIN\n",
    "        `concept` p_race_concept \n",
    "            ON person.race_concept_id = p_race_concept.concept_id \n",
    "    LEFT JOIN\n",
    "        `concept` p_ethnicity_concept \n",
    "            ON person.ethnicity_concept_id = p_ethnicity_concept.concept_id \n",
    "    LEFT JOIN\n",
    "        `concept` p_sex_at_birth_concept \n",
    "            ON person.sex_at_birth_concept_id = p_sex_at_birth_concept.concept_id  \n",
    "    WHERE\n",
    "        person.PERSON_ID IN (\n",
    "            SELECT\n",
    "                distinct person_id  \n",
    "            FROM\n",
    "                `cb_search_person` cb_search_person  \n",
    "            WHERE\n",
    "                cb_search_person.person_id IN (\n",
    "                    SELECT\n",
    "                        person_id \n",
    "                    FROM\n",
    "                        `cb_search_person` p \n",
    "                    WHERE\n",
    "                        has_whole_genome_variant = 1 \n",
    "                ) \n",
    "                AND cb_search_person.person_id IN (\n",
    "                    SELECT\n",
    "                        person_id \n",
    "                    FROM\n",
    "                        `person` p \n",
    "                    WHERE\n",
    "                        race_concept_id IN (8515) \n",
    "                ) \n",
    "            )\", sep=\"\")\n",
    "\n",
    "# Formulate a Cloud Storage destination path for the data exported from BigQuery.\n",
    "# NOTE: By default data exported multiple times on the same day will overwrite older copies.\n",
    "#       But data exported on a different days will write to a new location so that historical\n",
    "#       copies can be kept as the dataset definition is changed.\n",
    "person_25218662_path <- file.path(\n",
    "  Sys.getenv(\"WORKSPACE_BUCKET\"),\n",
    "  \"bq_exports\",\n",
    "  Sys.getenv(\"OWNER_EMAIL\"),\n",
    "  strftime(lubridate::now(), \"%Y%m%d\"),  # Comment out this line if you want the export to always overwrite.\n",
    "  \"person_25218662\",\n",
    "  \"person_25218662_*.csv\")\n",
    "message(str_glue('The data will be written to {person_25218662_path}. Use this path when reading ',\n",
    "                 'the data into your notebooks in the future.'))\n",
    "\n",
    "# Perform the query and export the dataset to Cloud Storage as CSV files.\n",
    "# NOTE: You only need to run `bq_table_save` once. After that, you can\n",
    "#       just read data from the CSVs in Cloud Storage.\n",
    "bq_table_save(\n",
    "  bq_dataset_query(Sys.getenv(\"WORKSPACE_CDR\"), dataset_25218662_person_sql, billing = Sys.getenv(\"GOOGLE_PROJECT\")),\n",
    "  person_25218662_path,\n",
    "  destination_format = \"CSV\")\n",
    "\n",
    "\n",
    "# Read the data directly from Cloud Storage into memory.\n",
    "# NOTE: Alternatively you can `gsutil -m cp {person_25218662_path}` to copy these files\n",
    "#       to the Jupyter disk.\n",
    "read_bq_export_from_workspace_bucket <- function(export_path) {\n",
    "  col_types <- cols(race = col_character(), ethnicity = col_character(), sex_at_birth = col_character())\n",
    "  bind_rows(\n",
    "    map(system2('gsutil', args = c('ls', export_path), stdout = TRUE, stderr = TRUE),\n",
    "        function(csv) {\n",
    "          message(str_glue('Loading {csv}.'))\n",
    "          chunk <- read_csv(pipe(str_glue('gsutil cat {csv}')), col_types = col_types, show_col_types = FALSE)\n",
    "          if (is.null(col_types)) {\n",
    "            col_types <- spec(chunk)\n",
    "          }\n",
    "          chunk\n",
    "        }))\n",
    "}\n",
    "dataset_25218662_person_df <- read_bq_export_from_workspace_bucket(person_25218662_path)\n",
    "\n",
    "dim(dataset_25218662_person_df)\n",
    "\n",
    "head(dataset_25218662_person_df, 5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dataset_25218662_person_df\n",
    "\n",
    "set.seed(1)\n",
    "select_patients = sample(x=1:dim(data)[1],size=1000)\n",
    "select_data = data[select_patients,]\n",
    "write.csv(select_data,file=\"/home/jupyter/workspaces/multiallelicgenesinvestigation/OUTPUT_SET_3/SAMPLE_SET_3.csv\",quote=FALSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample Set 4\n",
    "\n",
    "\n",
    "WGS, Mixed race group, Female or Male\n",
    "\n",
    "Random Selection # 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The data will be written to gs://fc-secure-efde03ca-418d-445e-84f1-df6f8f3f35d4/bq_exports/yebin@researchallofus.org/20230516/person_43228169/person_43228169_*.csv. Use this path when reading the data into your notebooks in the future.\n",
      "\n",
      "Loading gs://fc-secure-efde03ca-418d-445e-84f1-df6f8f3f35d4/bq_exports/yebin@researchallofus.org/20230516/person_43228169/person_43228169_000000000000.csv.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>1659</li><li>5</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 1659\n",
       "\\item 5\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 1659\n",
       "2. 5\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 1659    5"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A tibble: 5 × 5</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>person_id</th><th scope=col>date_of_birth</th><th scope=col>race</th><th scope=col>ethnicity</th><th scope=col>sex_at_birth</th></tr>\n",
       "\t<tr><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>2011744</td><td>1959-06-15 00:00:00 UTC</td><td>More than one population</td><td>Hispanic or Latino</td><td>Male</td></tr>\n",
       "\t<tr><td>1812234</td><td>1990-06-15 00:00:00 UTC</td><td>More than one population</td><td>Hispanic or Latino</td><td>Male</td></tr>\n",
       "\t<tr><td>1154390</td><td>1948-06-15 00:00:00 UTC</td><td>More than one population</td><td>Hispanic or Latino</td><td>Male</td></tr>\n",
       "\t<tr><td>1124763</td><td>1961-06-15 00:00:00 UTC</td><td>More than one population</td><td>Hispanic or Latino</td><td>Male</td></tr>\n",
       "\t<tr><td>1036175</td><td>1964-06-15 00:00:00 UTC</td><td>More than one population</td><td>Hispanic or Latino</td><td>Male</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A tibble: 5 × 5\n",
       "\\begin{tabular}{lllll}\n",
       " person\\_id & date\\_of\\_birth & race & ethnicity & sex\\_at\\_birth\\\\\n",
       " <dbl> & <chr> & <chr> & <chr> & <chr>\\\\\n",
       "\\hline\n",
       "\t 2011744 & 1959-06-15 00:00:00 UTC & More than one population & Hispanic or Latino & Male\\\\\n",
       "\t 1812234 & 1990-06-15 00:00:00 UTC & More than one population & Hispanic or Latino & Male\\\\\n",
       "\t 1154390 & 1948-06-15 00:00:00 UTC & More than one population & Hispanic or Latino & Male\\\\\n",
       "\t 1124763 & 1961-06-15 00:00:00 UTC & More than one population & Hispanic or Latino & Male\\\\\n",
       "\t 1036175 & 1964-06-15 00:00:00 UTC & More than one population & Hispanic or Latino & Male\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A tibble: 5 × 5\n",
       "\n",
       "| person_id &lt;dbl&gt; | date_of_birth &lt;chr&gt; | race &lt;chr&gt; | ethnicity &lt;chr&gt; | sex_at_birth &lt;chr&gt; |\n",
       "|---|---|---|---|---|\n",
       "| 2011744 | 1959-06-15 00:00:00 UTC | More than one population | Hispanic or Latino | Male |\n",
       "| 1812234 | 1990-06-15 00:00:00 UTC | More than one population | Hispanic or Latino | Male |\n",
       "| 1154390 | 1948-06-15 00:00:00 UTC | More than one population | Hispanic or Latino | Male |\n",
       "| 1124763 | 1961-06-15 00:00:00 UTC | More than one population | Hispanic or Latino | Male |\n",
       "| 1036175 | 1964-06-15 00:00:00 UTC | More than one population | Hispanic or Latino | Male |\n",
       "\n"
      ],
      "text/plain": [
       "  person_id date_of_birth           race                     ethnicity         \n",
       "1 2011744   1959-06-15 00:00:00 UTC More than one population Hispanic or Latino\n",
       "2 1812234   1990-06-15 00:00:00 UTC More than one population Hispanic or Latino\n",
       "3 1154390   1948-06-15 00:00:00 UTC More than one population Hispanic or Latino\n",
       "4 1124763   1961-06-15 00:00:00 UTC More than one population Hispanic or Latino\n",
       "5 1036175   1964-06-15 00:00:00 UTC More than one population Hispanic or Latino\n",
       "  sex_at_birth\n",
       "1 Male        \n",
       "2 Male        \n",
       "3 Male        \n",
       "4 Male        \n",
       "5 Male        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "library(tidyverse)\n",
    "library(bigrquery)\n",
    "\n",
    "# This query represents dataset \"All_WGS_multiple_FM\" for domain \"person\" and was generated for All of Us Controlled Tier Dataset v6\n",
    "dataset_43228169_person_sql <- paste(\"\n",
    "    SELECT\n",
    "        person.person_id,\n",
    "        person.birth_datetime as date_of_birth,\n",
    "        p_race_concept.concept_name as race,\n",
    "        p_ethnicity_concept.concept_name as ethnicity,\n",
    "        p_sex_at_birth_concept.concept_name as sex_at_birth \n",
    "    FROM\n",
    "        `person` person \n",
    "    LEFT JOIN\n",
    "        `concept` p_race_concept \n",
    "            ON person.race_concept_id = p_race_concept.concept_id \n",
    "    LEFT JOIN\n",
    "        `concept` p_ethnicity_concept \n",
    "            ON person.ethnicity_concept_id = p_ethnicity_concept.concept_id \n",
    "    LEFT JOIN\n",
    "        `concept` p_sex_at_birth_concept \n",
    "            ON person.sex_at_birth_concept_id = p_sex_at_birth_concept.concept_id  \n",
    "    WHERE\n",
    "        person.PERSON_ID IN (\n",
    "            SELECT\n",
    "                distinct person_id  \n",
    "            FROM\n",
    "                `cb_search_person` cb_search_person  \n",
    "            WHERE\n",
    "                cb_search_person.person_id IN (\n",
    "                    SELECT\n",
    "                        person_id \n",
    "                    FROM\n",
    "                        `cb_search_person` p \n",
    "                    WHERE\n",
    "                        has_whole_genome_variant = 1 \n",
    "                ) \n",
    "                AND cb_search_person.person_id IN (\n",
    "                    SELECT\n",
    "                        person_id \n",
    "                    FROM\n",
    "                        `person` p \n",
    "                    WHERE\n",
    "                        race_concept_id IN (2000000008) \n",
    "                ) \n",
    "                AND cb_search_person.person_id IN (\n",
    "                    SELECT\n",
    "                        person_id \n",
    "                    FROM\n",
    "                        `person` p \n",
    "                    WHERE\n",
    "                        sex_at_birth_concept_id IN (45878463, 45880669) \n",
    "                ) \n",
    "            )\", sep=\"\")\n",
    "\n",
    "# Formulate a Cloud Storage destination path for the data exported from BigQuery.\n",
    "# NOTE: By default data exported multiple times on the same day will overwrite older copies.\n",
    "#       But data exported on a different days will write to a new location so that historical\n",
    "#       copies can be kept as the dataset definition is changed.\n",
    "person_43228169_path <- file.path(\n",
    "  Sys.getenv(\"WORKSPACE_BUCKET\"),\n",
    "  \"bq_exports\",\n",
    "  Sys.getenv(\"OWNER_EMAIL\"),\n",
    "  strftime(lubridate::now(), \"%Y%m%d\"),  # Comment out this line if you want the export to always overwrite.\n",
    "  \"person_43228169\",\n",
    "  \"person_43228169_*.csv\")\n",
    "message(str_glue('The data will be written to {person_43228169_path}. Use this path when reading ',\n",
    "                 'the data into your notebooks in the future.'))\n",
    "\n",
    "# Perform the query and export the dataset to Cloud Storage as CSV files.\n",
    "# NOTE: You only need to run `bq_table_save` once. After that, you can\n",
    "#       just read data from the CSVs in Cloud Storage.\n",
    "bq_table_save(\n",
    "  bq_dataset_query(Sys.getenv(\"WORKSPACE_CDR\"), dataset_43228169_person_sql, billing = Sys.getenv(\"GOOGLE_PROJECT\")),\n",
    "  person_43228169_path,\n",
    "  destination_format = \"CSV\")\n",
    "\n",
    "# Read the data directly from Cloud Storage into memory.\n",
    "# NOTE: Alternatively you can `gsutil -m cp {person_43228169_path}` to copy these files\n",
    "#       to the Jupyter disk.\n",
    "read_bq_export_from_workspace_bucket <- function(export_path) {\n",
    "  col_types <- cols(race = col_character(), ethnicity = col_character(), sex_at_birth = col_character())\n",
    "  bind_rows(\n",
    "    map(system2('gsutil', args = c('ls', export_path), stdout = TRUE, stderr = TRUE),\n",
    "        function(csv) {\n",
    "          message(str_glue('Loading {csv}.'))\n",
    "          chunk <- read_csv(pipe(str_glue('gsutil cat {csv}')), col_types = col_types, show_col_types = FALSE)\n",
    "          if (is.null(col_types)) {\n",
    "            col_types <- spec(chunk)\n",
    "          }\n",
    "          chunk\n",
    "        }))\n",
    "}\n",
    "dataset_43228169_person_df <- read_bq_export_from_workspace_bucket(person_43228169_path)\n",
    "\n",
    "dim(dataset_43228169_person_df)\n",
    "\n",
    "head(dataset_43228169_person_df, 5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "code_folding": [
     3
    ]
   },
   "outputs": [],
   "source": [
    "data = dataset_43228169_person_df\n",
    "\n",
    "set.seed(1)\n",
    "select_patients = sample(x=1:dim(data)[1],size=1000)\n",
    "select_data = data[select_patients,]\n",
    "write.csv(select_data,file=\"/home/jupyter/workspaces/multiallelicgenesinvestigation/OUTPUT_SET_4/SAMPLE_SET_4.csv\",quote=FALSE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.2.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
